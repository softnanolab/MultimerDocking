_target_: lightning.pytorch.trainer.Trainer
default_root_dir: ./artifacts

deterministic: False

accelerator: gpu
devices: auto
strategy: 
  _target_: lightning.pytorch.strategies.DDPStrategy
  find_unused_parameters: True
  gradient_as_bucket_view: True
num_nodes: 1
precision: bf16-mixed
accumulate_grad_batches: 4
max_steps: 100000
logger:
  - _target_: lightning.pytorch.loggers.WandbLogger
    project: docking_model
    # name: ${hydra:job.name}
    save_dir: ${trainer.default_root_dir}/logger
    log_model: False

# Validation and checkpointing:
val_check_interval: 1000
enable_checkpointing: True
callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${trainer.default_root_dir}/checkpoints
    filename: "best_val_loss-{step:06d}"
    monitor: "val/loss"
    mode: "min"
    save_top_k: 1
    save_last: False

# Checkpointing every n steps:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${trainer.default_root_dir}/checkpoints
    filename: "periodic-{step:06d}"
    every_n_train_steps: 1000    
    save_top_k: 1                
    save_last: False

